{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "12662d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8f113cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_raw = \"He is the king . The king is royal . She is the royal queen\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "64b5f0cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['He', 'is', 'the', 'king'],\n",
       " ['The', 'king', 'is', 'royal'],\n",
       " ['She', 'is', 'the', 'royal', 'queen']]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_sentence = corpus_raw.split(\".\")\n",
    "sentences = []\n",
    "for sentence in raw_sentence:\n",
    "    sentences.append(sentence.strip().split())\n",
    "    \n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8c68384a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['He', 'is'],\n",
       " ['He', 'the'],\n",
       " ['is', 'He'],\n",
       " ['is', 'the'],\n",
       " ['is', 'king'],\n",
       " ['the', 'He'],\n",
       " ['the', 'is'],\n",
       " ['the', 'king'],\n",
       " ['king', 'is'],\n",
       " ['king', 'the'],\n",
       " ['The', 'king'],\n",
       " ['The', 'is'],\n",
       " ['king', 'The'],\n",
       " ['king', 'is'],\n",
       " ['king', 'royal'],\n",
       " ['is', 'The'],\n",
       " ['is', 'king'],\n",
       " ['is', 'royal'],\n",
       " ['royal', 'king'],\n",
       " ['royal', 'is'],\n",
       " ['She', 'is'],\n",
       " ['She', 'the'],\n",
       " ['is', 'She'],\n",
       " ['is', 'the'],\n",
       " ['is', 'royal'],\n",
       " ['the', 'She'],\n",
       " ['the', 'is'],\n",
       " ['the', 'royal'],\n",
       " ['the', 'queen'],\n",
       " ['royal', 'is'],\n",
       " ['royal', 'the'],\n",
       " ['royal', 'queen'],\n",
       " ['queen', 'the'],\n",
       " ['queen', 'royal']]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = []\n",
    "WINDOW_SIZE = 2\n",
    "\n",
    "for sentence in sentences:\n",
    "    for word_index, word in enumerate(sentence):\n",
    "        start_index = max(word_index - WINDOW_SIZE, 0)\n",
    "        end_index = min(word_index + WINDOW_SIZE + 1, len(sentence))\n",
    "        \n",
    "        for nb_word in sentence[start_index : word_index]:\n",
    "            data.append([word, nb_word])\n",
    "            \n",
    "        for nb_word in sentence[word_index+1 : end_index]:\n",
    "            data.append([word, nb_word])\n",
    "            \n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3d5e89c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'the': 0, 'She': 1, 'royal': 2, 'is': 3, 'queen': 4, 'The': 5, 'king': 6, 'He': 7}\n",
      "{0: 'the', 1: 'She', 2: 'royal', 3: 'is', 4: 'queen', 5: 'The', 6: 'king', 7: 'He'}\n"
     ]
    }
   ],
   "source": [
    "words = []\n",
    "for word in corpus_raw.split():\n",
    "    if word != '.':\n",
    "        words.append(word)\n",
    "words = set(words)\n",
    "\n",
    "word2int = {}\n",
    "int2word = {}\n",
    "vocab_size = len(words)\n",
    "\n",
    "for i, word in enumerate(words):\n",
    "    word2int[word] = i\n",
    "    int2word[i] = word\n",
    "    \n",
    "print(word2int)\n",
    "print(int2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "12aa1d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_one_hot(word_index, vocab_size):\n",
    "    temp = np.zeros(vocab_size)\n",
    "    temp[word_index] = 1\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "326bb5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = []\n",
    "y_train = []\n",
    "for word in data:\n",
    "    x_train.append(to_one_hot(word2int[word[0]], vocab_size))\n",
    "    y_train.append(to_one_hot(word2int[word[1]], vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "de0d2760",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0., 0., 0., 0., 0., 0., 0., 1.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 1.]),\n",
       " array([0., 0., 0., 1., 0., 0., 0., 0.])]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a1a8220b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " array([1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 1.])]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ff2a6d89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = np.asarray(x_train, dtype=np.float32)\n",
    "y_train = np.asarray(y_train, dtype=np.float32)\n",
    "\n",
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e7fbbe95",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Word2Vec:\n",
    "    def __init__(self, vocab_size=10, embedding_dim=5, optimizer='sgd', epochs=1000, learning_rate=0.01):\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        if optimizer == 'adam':\n",
    "            self.optimizer = tf.optimizers.Adam(learning_rate=learning_rate)\n",
    "        else:\n",
    "            self.optimizer = tf.optimizers.SGD(learning_rate=learning_rate)\n",
    "        self.epochs = epochs\n",
    "\n",
    "        self.W1 = tf.Variable(tf.random.normal([self.vocab_size, self.embedding_dim]))\n",
    "        self.b1 = tf.Variable(tf.random.normal([self.embedding_dim]))\n",
    "\n",
    "        self.W2 = tf.Variable(tf.random.normal([self.embedding_dim, self.vocab_size]))\n",
    "        self.b2 = tf.Variable(tf.random.normal([self.vocab_size]))\n",
    "\n",
    "    def vectorized(self, word_index):\n",
    "        return (self.W1 + self.b1)[word_index]\n",
    "\n",
    "\n",
    "    def train(self, x_train, y_train):\n",
    "        for i in range(self.epochs):\n",
    "            with tf.GradientTape() as tape:\n",
    "                hidden_layer = tf.add(tf.matmul(x_train, self.W1), self.b1)\n",
    "                output_layer = tf.add(tf.matmul(hidden_layer, self.W2), self.b2)\n",
    "\n",
    "                pred = tf.nn.softmax(output_layer)\n",
    "                loss = tf.reduce_mean(-tf.math.reduce_sum(y_train*tf.math.log(pred), axis=[1]))\n",
    "\n",
    "                grads = tape.gradient(loss, [self.W1, self.b1, self.W2, self.b2])\n",
    "                self.optimizer.apply_gradients(zip(grads, [self.W1, self.b1, self.W2, self.b2]))\n",
    "\n",
    "            if i % 1000 == 0:\n",
    "                print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1e4b31c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(6.1898546, shape=(), dtype=float32)\n",
      "tf.Tensor(1.3889955, shape=(), dtype=float32)\n",
      "tf.Tensor(1.3795668, shape=(), dtype=float32)\n",
      "tf.Tensor(1.3772283, shape=(), dtype=float32)\n",
      "tf.Tensor(1.3762264, shape=(), dtype=float32)\n",
      "tf.Tensor(1.3756828, shape=(), dtype=float32)\n",
      "tf.Tensor(1.3753462, shape=(), dtype=float32)\n",
      "tf.Tensor(1.375119, shape=(), dtype=float32)\n",
      "tf.Tensor(1.3749561, shape=(), dtype=float32)\n",
      "tf.Tensor(1.3748343, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "w2v = Word2Vec(vocab_size=vocab_size, embedding_dim=5, optimizer='SGD', epochs=10000, learning_rate=0.1)\n",
    "w2v.train(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f33157c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.6513228 , -2.119599  , -1.4017407 ,  1.6131532 , -0.99202585],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.vectorized(word2int['queen']).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1bd689bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.04989499, -1.8294151 , -1.1168658 ,  1.8642952 ,  2.4349895 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.vectorized(word2int['king']).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8a0afcbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([8, 5])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector = w2v.W1 + w2v.b1\n",
    "vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cfde28ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn import preprocessing\n",
    "\n",
    "model = TSNE(n_components=2, random_state=42)\n",
    "np.set_printoptions(suppress=True)\n",
    "vectors = model.fit_transform(vector)\n",
    "\n",
    "normalizer = preprocessing.Normalizer()\n",
    "vectors = normalizer.fit_transform(vectors,'l2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2ff24a52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "He [0.45033774 0.89285827]\n",
      "is [-0.24413551  0.9697411 ]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_xlim(left=-1, right=1)\n",
    "ax.set_ylim(bottom =-1, top=1)\n",
    "for word in words:\n",
    "    print(word, vectors[word2int[word]])\n",
    "    ax.annotate(word, (vectors[word2int[word]][0], vectors[word2int[word]][1]))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "59d33f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee111d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
