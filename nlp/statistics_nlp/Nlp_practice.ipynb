{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c5f2dcc",
   "metadata": {},
   "source": [
    "# TF-IDF 활용 핵심 키워드 추출"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34fb0da5",
   "metadata": {},
   "source": [
    "## 실습1. sklearn활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9a25f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56b74112",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests \n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "def get_news_by_url(url):\n",
    "  headers={\"user-agent\":\"Mozilla/5.0\"}\n",
    "  res = requests.get(url, headers=headers)\n",
    "  soup = BeautifulSoup(res.content, \"html.parser\")\n",
    "  content = soup.select_one(\"#articleBodyContents\").get_text().replace(\"\\n\", \"\")\n",
    "  content = content.replace(\"// flash 오류를 우회하기 위한 함수 추가function _flash_removeCallback() {}\", \"\")\n",
    "  \n",
    "  start_pos = re.search(r\"\\w+@\\w+\\.\\w+(.\\w+)?\", content).start()\n",
    "  content = content[:start_pos-1]\n",
    "  return content\n",
    "\n",
    "docs = []\n",
    "docs.append( get_news_by_url('https://news.naver.com/main/read.nhn?mode=LSD&mid=sec&sid1=105&oid=018&aid=0004430108') )\n",
    "docs.append( get_news_by_url('https://news.naver.com/main/read.nhn?mode=LSD&mid=sec&sid1=101&oid=001&aid=0011614790') )\n",
    "docs.append( get_news_by_url('https://news.naver.com/main/read.nhn?mode=LSD&mid=sec&sid1=102&oid=014&aid=0004424362') )\n",
    "docs.append( get_news_by_url('https://news.naver.com/main/read.nhn?mode=LSD&mid=sec&sid1=101&oid=119&aid=0002402191') )\n",
    "docs.append( get_news_by_url('https://news.naver.com/main/read.nhn?mode=LSD&mid=sec&sid1=101&oid=030&aid=0002882728') )\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24b0003",
   "metadata": {},
   "source": [
    "### 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e36d0a6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'과기 정통부 장관 참석 기념행사 투입 여종 데이터 구축 민간 외부 연계 체계 개방 강화 기자 국가 차원 빅 데이터 활용 시대 산업 창출 기존 산업 변화 이르 혁신 장 센터 문 분야'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from konlpy.tag import Mecab\n",
    "mecab = Mecab()\n",
    "\n",
    "preprocessed_docs = []\n",
    "\n",
    "\n",
    "for doc in docs:\n",
    "  token_list = []\n",
    "  for token in mecab.pos(doc):\n",
    "    if token[1] in ['NNG', 'VV']:\n",
    "      token_list.append(token[0])\n",
    "  preprocessed_docs.append(\" \".join(token_list))\n",
    "\n",
    "\n",
    "preprocessed_docs[0][:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a095756b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['가공', '가능', '가입자', '가족', '가중치', '가치', '각종', '감소', '감염', '강국']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vect = CountVectorizer(max_df=0.85, max_features=10000)\n",
    "word_count = count_vect.fit_transform(preprocessed_docs)\n",
    "print((count_vect.get_feature_names()[:10]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1022710",
   "metadata": {},
   "source": [
    "### TF-IDF 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bcfaf98c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfTransformer()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "tfidf_transformer = TfidfTransformer(smooth_idf=True, use_idf=True)\n",
    "tfidf_transformer.fit(word_count)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994502cc",
   "metadata": {},
   "source": [
    "### 핵심 키워드 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ea42a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_keywords(keywords):\n",
    "    return sorted(zip(keywords.col, keywords.data), key=lambda x: (x[1], x[0]), reverse=True)\n",
    " \n",
    "def extract_keywords(feature_names, sorted_keywords, n=5):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c36e8317",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'coo_matrix' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-7ddb8e30205e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mfeature_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcount_vect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtfidf_vect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfidf_transformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcount_vect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0msort_keywords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtfidf_vect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtocoo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-25-c4f7b3225ae4>\u001b[0m in \u001b[0;36msort_keywords\u001b[0;34m(tfidf)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msort_keywords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtfidf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtfidf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mextract_keywords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_keywords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted_keywords\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/nlp/lib/python3.8/site-packages/scipy/sparse/base.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgetmaxprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'coo_matrix' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "doc = preprocessed_docs[0] # 핵심키워드 추출할 문서 조회\n",
    "\n",
    "feature_names = count_vect.get_feature_names()\n",
    "tfidf_vect = tfidf_transformer.transform(count_vect.transform([doc]))\n",
    "sort_keywords(tfidf_vect.tocoo())[:10]\n",
    "\n",
    "\n",
    "# 사용자가 지정한 갯수만큼 키워드 추출\n",
    "keywords = extract_keywords(feature_names, sorted_keywords, 5)\n",
    " \n",
    "print(\"\\n===== 원문 =====\")\n",
    "print(docs[0][:100])\n",
    "print(\"\\n=== 핵심키워드 ===\")\n",
    "for k in keywords:\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6d5ecd59",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x393 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 201 stored elements in COOrdinate format>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "27cb2158",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([391, 387, 385, 382, 380, 379, 378, 377, 375, 374, 373, 372, 371,\n",
       "       370, 369, 365, 362, 361, 360, 359, 358, 355, 354, 352, 349, 347,\n",
       "       346, 345, 338, 337, 336, 335, 333, 332, 330, 328, 327, 326, 325,\n",
       "       323, 321, 320, 319, 317, 316, 314, 308, 307, 306, 301, 299, 294,\n",
       "       289, 288, 286, 285, 284, 283, 282, 281, 280, 276, 274, 270, 268,\n",
       "       265, 263, 259, 256, 251, 247, 246, 245, 241, 240, 239, 237, 234,\n",
       "       233, 231, 229, 228, 227, 226, 223, 222, 221, 219, 216, 214, 213,\n",
       "       212, 211, 210, 209, 204, 203, 198, 195, 194, 192, 189, 185, 184,\n",
       "       182, 181, 180, 179, 178, 177, 175, 172, 171, 166, 163, 162, 161,\n",
       "       160, 152, 151, 150, 147, 146, 144, 142, 139, 135, 134, 132, 129,\n",
       "       128, 126, 122, 121, 118, 115, 113, 110, 109, 108, 107, 105, 103,\n",
       "       102, 101, 100,  98,  95,  91,  88,  87,  86,  83,  81,  80,  77,\n",
       "        76,  75,  73,  71,  68,  67,  64,  62,  61,  59,  58,  55,  54,\n",
       "        52,  51,  49,  48,  47,  46,  45,  43,  41,  38,  37,  36,  35,\n",
       "        34,  33,  32,  31,  30,  29,  28,  26,  25,  24,  21,  18,  15,\n",
       "        14,  12,  11,   9,   7,   1], dtype=int32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vect.tocoo().col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fa9c2f62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.03703823, 0.18780025, 0.07407646, 0.07407646, 0.03703823,\n",
       "       0.03703823, 0.03703823, 0.02988221, 0.03703823, 0.14941106,\n",
       "       0.03703823, 0.03703823, 0.02988221, 0.03703823, 0.07407646,\n",
       "       0.03703823, 0.05976443, 0.03703823, 0.25926763, 0.03703823,\n",
       "       0.02988221, 0.03703823, 0.02988221, 0.02988221, 0.03703823,\n",
       "       0.1111147 , 0.03703823, 0.1111147 , 0.03703823, 0.02988221,\n",
       "       0.03703823, 0.07407646, 0.03703823, 0.04173339, 0.02988221,\n",
       "       0.07407646, 0.03703823, 0.03703823, 0.1111147 , 0.03703823,\n",
       "       0.1111147 , 0.03703823, 0.03703823, 0.02988221, 0.03703823,\n",
       "       0.03703823, 0.02988221, 0.02988221, 0.03703823, 0.03703823,\n",
       "       0.1111147 , 0.07407646, 0.02988221, 0.03703823, 0.12402468,\n",
       "       0.07407646, 0.18519116, 0.02988221, 0.04173339, 0.02988221,\n",
       "       0.08964664, 0.07407646, 0.03703823, 0.03703823, 0.03703823,\n",
       "       0.02988221, 0.1111147 , 0.03703823, 0.03703823, 0.02988221,\n",
       "       0.03703823, 0.03703823, 0.03703823, 0.03703823, 0.02480494,\n",
       "       0.03703823, 0.08964664, 0.03703823, 0.03703823, 0.03703823,\n",
       "       0.05976443, 0.03703823, 0.03703823, 0.05976443, 0.03703823,\n",
       "       0.07407646, 0.03703823, 0.03703823, 0.03703823, 0.02988221,\n",
       "       0.1111147 , 0.03703823, 0.07407646, 0.03703823, 0.14815293,\n",
       "       0.1111147 , 0.07407646, 0.03703823, 0.02988221, 0.07407646,\n",
       "       0.08964664, 0.03703823, 0.03703823, 0.05976443, 0.03703823,\n",
       "       0.03703823, 0.03703823, 0.03703823, 0.03703823, 0.07407646,\n",
       "       0.22953363, 0.02988221, 0.07407646, 0.04173339, 0.03703823,\n",
       "       0.05976443, 0.02988221, 0.14815293, 0.07407646, 0.07441481,\n",
       "       0.07407646, 0.03703823, 0.03703823, 0.04960987, 0.03703823,\n",
       "       0.03703823, 0.14941106, 0.08964664, 0.03703823, 0.03703823,\n",
       "       0.03703823, 0.02988221, 0.14815293, 0.07407646, 0.02988221,\n",
       "       0.03703823, 0.09921974, 0.14815293, 0.03703823, 0.07407646,\n",
       "       0.03703823, 0.03703823, 0.03703823, 0.03703823, 0.03703823,\n",
       "       0.03703823, 0.11952885, 0.02480494, 0.03703823, 0.03703823,\n",
       "       0.07407646, 0.07407646, 0.03703823, 0.03703823, 0.03703823,\n",
       "       0.03703823, 0.03703823, 0.02988221, 0.03703823, 0.03703823,\n",
       "       0.05976443, 0.03703823, 0.14941106, 0.04960987, 0.05976443,\n",
       "       0.03703823, 0.02480494, 0.08964664, 0.03703823, 0.02988221,\n",
       "       0.03703823, 0.02988221, 0.03703823, 0.17929328, 0.03703823,\n",
       "       0.07407646, 0.07407646, 0.03703823, 0.05976443, 0.18519116,\n",
       "       0.03703823, 0.02988221, 0.03703823, 0.07407646, 0.03703823,\n",
       "       0.04173339, 0.03703823, 0.22222939, 0.03703823, 0.11952885,\n",
       "       0.07407646, 0.02480494, 0.03703823, 0.02988221, 0.03703823,\n",
       "       0.08964664, 0.03703823, 0.03703823, 0.03703823, 0.02988221,\n",
       "       0.02086669])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vect.tocoo().data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f46ebb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class A():\n",
    "    def __init__(self):\n",
    "        print(\"A\")\n",
    "    def __str__(self):\n",
    "        return \"I am A\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aff0921d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A\n",
      "<class '__main__.A'>\n"
     ]
    }
   ],
   "source": [
    "a = A()\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac79855",
   "metadata": {},
   "source": [
    "## gensim 활용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d16c01",
   "metadata": {},
   "source": [
    "### 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c6c8657c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'과기 정통부 일 유영민 장관 등 참석 기념행사 년 억 원 투입 여종 데이터 구축 민간 클라우드 통한 외부 연계 체계 개방 강화 데일리 이재운 기자 국가 차원 빅 데이터 활용 시대 '"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from konlpy.tag import Mecab\n",
    "mecab = Mecab()\n",
    "\n",
    "preprocessed_docs = []\n",
    "for doc in docs :\n",
    "  # 명사와 동사만으로 문서 전처리\n",
    "  preprocessed_docs.append(' '.join([token[0] for token in mecab.pos(doc) if token[1][0] in ['N', 'V']]))\n",
    "preprocessed_docs[0][:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9a8090",
   "metadata": {},
   "source": [
    "### TF-IDF 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "452906b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hosung/opt/anaconda3/envs/nlp/lib/python3.8/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import TfidfModel\n",
    "from gensim.corpora import Dictionary\n",
    "\n",
    "document_ls = [doc.split() for doc in preprocessed_docs]\n",
    "dct = Dictionary(document_ls) # 인덱스(key) - 단어(valuue) 인 딕셔너리 생성\n",
    "corpus = [dct.doc2bow(doc) for doc in document_ls] # 각 문서에 포함된 단어를 인덱스로 변환하여 corpus 생성\n",
    "tfidf = TfidfModel(corpus) # TF-IDF 산출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4a37a9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_keywords(tfidf):\n",
    "    return sorted(tfidf, key=lambda x: (x[1], x[0]), reverse=True)\n",
    "\n",
    "def extract_keywords(feature_names, sorted_keywords, n=5):\n",
    "    return [(feature_names[idx], score) for idx, score in sorted_keywords[:n]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "800b168b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 핵심키워드 ===\n",
      "('플랫', 0.2495222182663338)\n",
      "('폼', 0.2495222182663338)\n",
      "('계획', 0.21387618708542896)\n",
      "('정통부', 0.17823015590452412)\n",
      "('위한', 0.17823015590452412)\n"
     ]
    }
   ],
   "source": [
    "doc = corpus[0]\n",
    "\n",
    "sorted_keywords = sort_keywords(tfidf[doc]) # TF-IDF를 기준으로 역순 정렬\n",
    "\n",
    "# 사용자가 지정한 갯수만큼 키워드 추출\n",
    "keywords = extract_keywords(dct, sorted_keywords, 5)\n",
    "print(keywords)\n",
    "print(\"\\n==== 원문 =====\")\n",
    "\n",
    "print(\"\\n=== 핵심키워드 ===\")\n",
    "for k in keywords:\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a96dc5b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'바나나': 0, '사과': 1, '파인애플': 2, '딸기': 3}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = ['딸기', '바나나', '사과', '딸기', '파인애플']\n",
    "nodes = ['바나나', '사과', '파인애플', '딸기']\n",
    "vocab = nodes\n",
    "\n",
    "vocab2idx = {vocab[i]:i for i in range(0, len(vocab))} #vocab을 인덱스로 변환\n",
    "idx2vocab = {i:vocab[i] for i in range(0, len(vocab))} #인덱스를 vocab으로 변환\n",
    "vocab2idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee4ca9a",
   "metadata": {},
   "source": [
    "3) 그래프 생성 (weighted edge 계산)\n",
    "\n",
    "- TextRank는 그래프 기반 모델\n",
    "- 각 단어(토큰)은 그래프의 노드(vertex)\n",
    "- weighted_edge 행렬은 노드간 가중치 정보를 담고 있음\n",
    "- weighted_edge[i][j] 는 i번째 단어와 j번째 단어의 가중치를 의미\n",
    "- weighted_edge[i][j] 가 0인 경우는 노드간 연결이 없음을 의미\n",
    "- 모든 노드는 1로 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4cca0c42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['딸기', '바나나']\n",
      "['바나나', '사과']\n",
      "['사과', '딸기']\n",
      "['딸기', '파인애플']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "vocab_len = len(vocab)\n",
    "\n",
    "# 토큰별로 그래프 edge를 Matrix 형태로 생성\n",
    "weighted_edge = np.zeros((vocab_len,vocab_len),dtype=np.float32)\n",
    "\n",
    "# 각 토큰 노드별로 스코어 1로 초기화\n",
    "score = np.ones((vocab_len),dtype=np.float32)\n",
    "\n",
    "# coocurrence를 판단하기 위한 window 사이즈 설정\n",
    "window_size = 2\n",
    "covered_cooccurence = []\n",
    "\n",
    "for window_start in range(0, (len(tokens) - window_size + 1)):\n",
    "    window = tokens[window_start : window_start + window_size]\n",
    "    print(window)\n",
    "    \n",
    "    for i in range(window_size):\n",
    "        for j in range(i + 1, window_size):\n",
    "            if(window[i] in vocab and window[j] in vocab):\n",
    "                index_i = i + window_start\n",
    "                index_j = j + window_start\n",
    "                \n",
    "                if [index_i, index_j] not in covered_cooccurence:\n",
    "                    weighted_edge[vocab2idx[window[i]]][vocab2idx[window[j]]] = 1\n",
    "                    weighted_edge[vocab2idx[window[j]]][vocab2idx[window[i]]] = 1\n",
    "                    covered_cooccurence.append((index_i, index_j))\n",
    "                    \n",
    "for i in range(vocab_len):\n",
    "    row_sum = weighted_edge[i].sum()\n",
    "    print(f\"{i} : {row_sum}\")\n",
    "    weighted_edge[i] = weighted_edge[i]/row_sum\n",
    "    \n",
    "print(weighted_edge)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c3a0c6",
   "metadata": {},
   "source": [
    "### 핵심 단어 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72107a89",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-2-af9387c06e74>, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-af9387c06e74>\"\u001b[0;36m, line \u001b[0;32m5\u001b[0m\n\u001b[0;31m    print(\"\\n ===핵심 키워드 ===\")\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "print(np.argsort(score))\n",
    "sorted_index = np.flip(np.argsort(score), 0)\n",
    "\n",
    "n = 4\n",
    " print(\"\\n ===핵심 키워드 ===\")\n",
    "    for i in range(0, n):\n",
    "        print(str(idx2vocab[sorted_index[i]])+\" : \" + str(score[sorted_index[i]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e6c164",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "73d4940103e11300043f00ad330523cc1a06dd889af7ec99652e23643049fdd9"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
